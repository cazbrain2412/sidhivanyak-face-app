"use client";

import { useEffect, useRef, useState } from "react";
import { useRouter } from "next/navigation";

export default function SupervisorUniversalEnrollPage() {
  const router = useRouter();

  const videoRef = useRef(null);
  const streamRef = useRef(null);

  const [cameraFacing, setCameraFacing] = useState("user"); // user | environment
  const [status, setStatus] = useState("initialising camera…");
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [samples, setSamples] = useState([]);
  const [busy, setBusy] = useState(false);

  // ---------- CAMERA + MODELS ----------
  useEffect(() => {
    let cancelled = false;

    async function init() {
      try {
        setStatus("requesting camera…");

        if (streamRef.current) {
          streamRef.current.getTracks().forEach(t => t.stop());
        }

        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: cameraFacing }
        });

        if (cancelled) return;

        streamRef.current = stream;
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }

        setStatus("loading face models…");
        const faceapi = await import("face-api.js");

        try {
          if (faceapi?.tf?.setBackend) {
            await faceapi.tf.setBackend("webgl");
            await faceapi.tf.ready();
          }
        } catch {}

        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
          faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
          faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
        ]);

        if (cancelled) return;
        setModelsLoaded(true);
        setStatus("camera ready — capture 3 samples");
      } catch (err) {
        console.error(err);
        setStatus("camera error");
      }
    }

    init();

    return () => {
      cancelled = true;
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(t => t.stop());
      }
    };
  }, [cameraFacing]);

  // ---------- CAPTURE ----------
  async function captureSample() {
    if (busy || !modelsLoaded) return;
    setBusy(true);

    try {
      const faceapi = await import("face-api.js");

      const detection = await faceapi
        .detectSingleFace(videoRef.current, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) {
        setStatus("no face detected — look at camera");
        setBusy(false);
        return;
      }

      const descriptor = Array.from(detection.descriptor);
      setSamples(prev => {
        const next = [...prev, descriptor];
        setStatus(`sample ${next.length}/3 captured`);
        return next;
      });
    } catch (err) {
      console.error(err);
      setStatus("capture failed");
    } finally {
      setBusy(false);
    }
  }

  // ---------- SAVE ----------
  async function saveFace() {
    if (samples.length < 3) return;

    setBusy(true);
    setStatus("saving face…");

    try {
      const token = localStorage.getItem("supervisorToken");

      const res = await fetch("/api/supervisor/enroll-face", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: token ? `Bearer ${token}` : "",
        },
        body: JSON.stringify({ samples }),
      });

      const data = await res.json();
      if (!data.success) {
        setStatus(data.message || "save failed");
        return;
      }

      setStatus("✅ face enrolled successfully");
      setSamples([]);
    } catch (err) {
      console.error(err);
      setStatus("server error");
    } finally {
      setBusy(false);
    }
  }

  return (
    <div className="p-4 max-w-md mx-auto">
      <h2 className="text-lg font-semibold mb-2">Supervisor Face Enroll</h2>

      <video
        ref={videoRef}
        autoPlay
        muted
        playsInline
        className="w-full h-72 rounded-lg bg-black object-cover"
      />

      <div className="text-sm text-gray-600 mt-2">{status}</div>

      <div className="flex gap-2 mt-3">
        <button
          onClick={() =>
            setCameraFacing(f => (f === "user" ? "environment" : "user"))
          }
          className="px-3 py-2 rounded bg-gray-200"
        >
          Switch Camera
        </button>

        <button
          disabled={busy || !modelsLoaded}
          onClick={captureSample}
          className="px-3 py-2 rounded bg-indigo-600 text-white"
        >
          Capture
        </button>

        <button
          disabled={samples.length < 3 || busy}
          onClick={saveFace}
          className="px-3 py-2 rounded bg-green-600 text-white"
        >
          Save
        </button>
      </div>

      <div className="mt-2 text-sm">
        Samples: {samples.length}/3
      </div>

      <button
        onClick={() => router.back()}
        className="mt-4 text-sm text-blue-600"
      >
        ← Back
      </button>
    </div>
  );
}

